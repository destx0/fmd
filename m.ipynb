{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pyfhel in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from Pyfhel) (1.25.2)\n",
      "Requirement already satisfied: pynacl in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from pynacl) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from cffi>=1.4.1->pynacl) (2.22)\n",
      "Requirement already satisfied: cryptography in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (42.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from cryptography) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from cffi>=1.12->cryptography) (2.22)\n",
      "Requirement already satisfied: tqdm in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pyfhel\n",
    "!pip install pynacl\n",
    "!pip install cryptography\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_clients = 3\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 21:28:16.654094: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-17 21:28:16.654162: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-17 21:28:16.654653: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-17 21:28:16.715349: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 21:28:17.692192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.14.1\n",
      "GPUs available: 1\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 21:28:19.320168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:19.416327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:19.416619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    print(\"GPUs available:\", len(gpus))\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyfhel\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "# from src.models.FMLEE import FMLEE\n",
    "# from src.data.load_data import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_dir = \"dataset/mnist_data/\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class MAML(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(MAML, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        return self.model(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"model\": self.model.get_config()}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        model = tf.keras.models.Model.from_config(config[\"model\"])\n",
    "        return cls(model)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        y_pred = self.model(x)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMLEE:\n",
    "    def __init__(self, no_clients, epochs):\n",
    "        self.no_clients = no_clients\n",
    "        self.epochs = epochs\n",
    "        self.HE = self.CKKS()\n",
    "        self.clients = []\n",
    "        self.init_clients()\n",
    "\n",
    "    def model_spec(self):\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "                ),\n",
    "                tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "                tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(10),\n",
    "            ]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def init_model(self):\n",
    "        model = MAML(self.model_spec())\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def CKKS(self):\n",
    "        HE = Pyfhel()\n",
    "        ckks_params = {\n",
    "            \"scheme\": \"CKKS\",\n",
    "            \"n\": 2**14,  # Polynomial modulus degree. For CKKS, n/2 values can be\n",
    "            \"scale\": 2**30,  # All the encodings will use it for float->fixed point\n",
    "            \"qi_sizes\": [\n",
    "                60,\n",
    "                30,\n",
    "                30,\n",
    "                30,\n",
    "                60,\n",
    "            ],\n",
    "        }\n",
    "        HE.contextGen(**ckks_params)  # Generate context for ckks scheme\n",
    "        HE.keyGen()  # Key Generation: generates a pair of public/secret keys\n",
    "        HE.rotateKeyGen()\n",
    "        HE.relinKeyGen()\n",
    "        return HE\n",
    "\n",
    "    def init_clients(self):\n",
    "        for i in range(self.no_clients):\n",
    "            self.clients.append(self.init_model())\n",
    "            print(f\"Client {i} initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_save_mnist(save_dir):\n",
    "    (x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Save training data with progress bar\n",
    "    for array, name in zip(\n",
    "        [x_train_all, y_train_all, x_test, y_test],\n",
    "        [\"x_train.npy\", \"y_train.npy\", \"x_test.npy\", \"y_test.npy\"],\n",
    "    ):\n",
    "        with tqdm(total=len(array), desc=f\"Saving {name}\") as pbar:\n",
    "            np.save(os.path.join(save_dir, name), array)\n",
    "            pbar.update(len(array))\n",
    "\n",
    "    print(f\"Dataset downloaded and saved locally at {save_dir}\")\n",
    "\n",
    "\n",
    "def load_mnist_from_local(save_dir):\n",
    "    x_train_all = np.load(os.path.join(save_dir, \"x_train.npy\"))\n",
    "    y_train_all = np.load(os.path.join(save_dir, \"y_train.npy\"))\n",
    "    x_test = np.load(os.path.join(save_dir, \"x_test.npy\"))\n",
    "    y_test = np.load(os.path.join(save_dir, \"y_test.npy\"))\n",
    "    print(f\"Dataset loaded from local files at {save_dir}\")\n",
    "    x_train_all = x_train_all.astype(np.float32) / 255\n",
    "    x_test = x_test.astype(np.float32) / 255\n",
    "\n",
    "    return (x_train_all, y_train_all), (x_test, y_test)\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    if not os.path.exists(os.path.join(save_dir, \"x_train.npy\")):\n",
    "        download_and_save_mnist(save_dir)\n",
    "    return load_mnist_from_local(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 initialized.\n",
      "Client 1 initialized.\n",
      "Client 2 initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 21:28:20.410317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:20.410577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:20.410748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:20.503393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:20.503586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:20.503748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-17 21:28:20.503876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2766 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "fml = FMLEE(no_clients, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.MAML at 0x767e5d6695e0>,\n",
       " <__main__.MAML at 0x767e5c7acc70>,\n",
       " <__main__.MAML at 0x767e5c74f7f0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fml.clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ckks Pyfhel obj at 0x767e5cbe47b0, [pk:Y, sk:Y, rtk:Y, rlk:Y, contx(n=16384, t=0, sec=128, qi=[60, 30, 30, 30, 60], scale=1073741824.0, )]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fml.HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from local files at dataset/mnist_data/\n"
     ]
    }
   ],
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test)  = load_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 21:28:21.427867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-06-17 21:28:21.516768: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:521] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  /home/voy/.conda/envs/he39/lib/python3.9/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/voy/.conda/envs/he39/lib/python3.9/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2024-06-17 21:28:21.519600: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.519626: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.519647: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.519665: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.519691: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.519712: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.519736: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.519758: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:559] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "2024-06-17 21:28:21.521531: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-17 21:28:21.521585: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-17 21:28:21.621276: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-17 21:28:21.621760: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-17 21:28:21.621788: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-06-17 21:28:21.622063: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-17 21:28:21.622111: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:322] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-06-17 21:28:21.860409: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-17 21:28:21.861202: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-17 21:28:21.861233: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-06-17 21:28:21.861499: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-17 21:28:21.861539: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node Adam/Pow defined at (most recent call last):\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_6509/2761664708.py\", line 1, in <module>\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/tmp/ipykernel_6509/1367028437.py\", line 29, in train_step\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/optimizers/legacy/optimizer_v2.py\", line 752, in apply_gradients\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/optimizers/legacy/optimizer_v2.py\", line 1119, in _prepare\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/optimizers/legacy/adam.py\", line 143, in _prepare_local\n\nJIT compilation failed.\n\t [[{{node Adam/Pow}}]] [Op:__inference_train_function_1263]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_all\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node Adam/Pow defined at (most recent call last):\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_6509/2761664708.py\", line 1, in <module>\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/tmp/ipykernel_6509/1367028437.py\", line 29, in train_step\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/optimizers/legacy/optimizer_v2.py\", line 752, in apply_gradients\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/optimizers/legacy/optimizer_v2.py\", line 1119, in _prepare\n\n  File \"/home/voy/.conda/envs/he39/lib/python3.9/site-packages/keras/src/optimizers/legacy/adam.py\", line 143, in _prepare_local\n\nJIT compilation failed.\n\t [[{{node Adam/Pow}}]] [Op:__inference_train_function_1263]"
     ]
    }
   ],
   "source": [
    "fml.clients[0].fit(x_train_all, y_train_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
