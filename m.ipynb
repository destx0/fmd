{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pyfhel in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from Pyfhel) (1.25.2)\n",
      "Requirement already satisfied: pynacl in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from pynacl) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from cffi>=1.4.1->pynacl) (2.22)\n",
      "Requirement already satisfied: cryptography in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (42.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from cryptography) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (from cffi>=1.12->cryptography) (2.22)\n",
      "Requirement already satisfied: tqdm in /home/voy/.conda/envs/he39/lib/python3.9/site-packages (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pyfhel\n",
    "!pip install pynacl\n",
    "!pip install cryptography\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_clients = 3\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.14.1\n",
      "GPUs available: 1\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    print(\"GPUs available:\", len(gpus))\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from local files.\n",
      "x_train_all shape: (60000, 28, 28)\n",
      "y_train_all shape: (60000,)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "save_dir = \"dataset/mnist_data/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def download_and_save_mnist(save_dir):\n",
    "    (x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    np.save(os.path.join(save_dir, \"x_train.npy\"), x_train_all)\n",
    "    np.save(os.path.join(save_dir, \"y_train.npy\"), y_train_all)\n",
    "    np.save(os.path.join(save_dir, \"x_test.npy\"), x_test)\n",
    "    np.save(os.path.join(save_dir, \"y_test.npy\"), y_test)\n",
    "    print(\"Dataset downloaded and saved locally.\")\n",
    "\n",
    "\n",
    "def load_mnist_from_local(save_dir):\n",
    "    x_train_all = np.load(os.path.join(save_dir, \"x_train.npy\"))\n",
    "    y_train_all = np.load(os.path.join(save_dir, \"y_train.npy\"))\n",
    "    x_test = np.load(os.path.join(save_dir, \"x_test.npy\"))\n",
    "    y_test = np.load(os.path.join(save_dir, \"y_test.npy\"))\n",
    "    print(\"Dataset loaded from local files.\")\n",
    "    return (x_train_all, y_train_all), (x_test, y_test)\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(save_dir, \"x_train.npy\")):\n",
    "    download_and_save_mnist(save_dir)\n",
    "\n",
    "(x_train_all, y_train_all), (x_test, y_test) = load_mnist_from_local(save_dir)\n",
    "\n",
    "print(f\"x_train_all shape: {x_train_all.shape}\")\n",
    "print(f\"y_train_all shape: {y_train_all.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "x_train_all = x_train_all.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMLEE:\n",
    "    def __init__(self, no_clients, epochs):\n",
    "        self.no_clients = no_clients\n",
    "        self.epochs = epochs\n",
    "        self.clients = []\n",
    "        self.init_clients()\n",
    "        \n",
    "    def init_model(self):\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "                ),\n",
    "                tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "                tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(10),\n",
    "            ]\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def init_clients(self):\n",
    "        for i in range(self.no_clients):\n",
    "            self.clients.append(self.init_model())\n",
    "            print(f\"Client {i} initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 initialized.\n",
      "Client 2 initialized.\n"
     ]
    }
   ],
   "source": [
    "fml = FMLEE(no_clients, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.engine.sequential.Sequential at 0x7b3960c80640>,\n",
       " <keras.src.engine.sequential.Sequential at 0x7b3960e033a0>,\n",
       " <keras.src.engine.sequential.Sequential at 0x7b3960b21ac0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fml.clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 12:45:23.116450: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-16 12:45:23.116486: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-16 12:45:23.116517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-16 12:45:23.122996: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-16 12:45:23.767920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_data import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving x_train.npy: 100%|██████████| 60000/60000 [00:00<00:00, 2492702.31it/s]\n",
      "Saving y_train.npy: 100%|██████████| 60000/60000 [00:00<00:00, 221920846.56it/s]\n",
      "Saving x_test.npy: 100%|██████████| 10000/10000 [00:00<00:00, 2135918.93it/s]\n",
      "Saving y_test.npy: 100%|██████████| 10000/10000 [00:00<00:00, 54260077.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and saved locally at dataset/mnist_data/\n",
      "Dataset loaded from local files at dataset/mnist_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test)  = load_mnist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
